{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc12d56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import torch\n",
    "import torch.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "153d3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.ModelNet40 import ModelNet40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0779d88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5114\n",
      "dict_keys(['pointcloud_a', 'pointcloud_b', 'transformation_matrix', 'class'])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ModelNet40('train')\n",
    "test_dataset = ModelNet40('test')\n",
    "cross_dataset = ModelNet40('cross-category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f8bbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization import visualize_pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2631a35a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859a0882d99c45aab806d0bf688b5f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_pointclouds(train_dataset[1000]['pointcloud_a'].T,train_dataset[1000]['pointcloud_b'].T,0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba847522",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed6612f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5138873",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26049d",
   "metadata": {},
   "source": [
    "# Pointmixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e0a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.pointmixer import PointMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e308ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape is torch.Size([2, 128, 1024]) torch.Size([2, 128, 1024])\n"
     ]
    }
   ],
   "source": [
    "cloud_a, cloud_b = torch.rand(2, 3, 1024), torch.rand(2, 3, 1024)\n",
    "pm = PointMixer(two_pooling=False)\n",
    "mixer_a, mixer_b = pm(cloud_a, cloud_b)\n",
    "print(\"output shape is\", mixer_a.shape, mixer_b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0ecd6",
   "metadata": {},
   "source": [
    "# Feature Interaction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "595aa9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.featureinteraction import FeatureInteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "451543e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fusion1 and fusion2 output shapes are torch.Size([2, 256, 1024]) torch.Size([2, 256, 1024])\n"
     ]
    }
   ],
   "source": [
    "feat1, feat2 = torch.rand((2, 128, 1024)), torch.rand((2, 128, 1024))\n",
    "feature_interaction = FeatureInteraction()\n",
    "fusion1, fusion2 = feature_interaction(feat1, feat2)\n",
    "print(\"fusion1 and fusion2 output shapes are\", fusion1.shape, fusion2.shape)\n",
    "assert fusion1.shape == (2, 256, 1024)\n",
    "assert fusion2.shape == (2, 256, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e438a59a",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b84d1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.decoder import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b9d7fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape is  torch.Size([2, 3, 1024])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((2, 256, 1024)) # (batches, channels, number of points)\n",
    "decoder = Decoder(256)\n",
    "output = decoder(x)\n",
    "print(\"output shape is \", output.shape)\n",
    "assert output.shape == (2, 3, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519eb68e",
   "metadata": {},
   "source": [
    "# Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54f4d113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape is torch.Size([2, 128, 1024]) torch.Size([2, 128, 1024])\n",
      "\n",
      "fusion1 and fusion2 output shapes are torch.Size([2, 256, 1024]) torch.Size([2, 256, 1024])\n",
      "\n",
      "output shape cloud A  torch.Size([2, 3, 1024])\n",
      "\n",
      "output shape cloud B  torch.Size([2, 3, 1024])\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(train_dataloader):\n",
    "    cloud_a, cloud_b = j[\"input\"].float(), j[\"output\"].float()\n",
    "    pm = PointMixer(two_pooling=False)\n",
    "    mixer_a, mixer_b = pm(cloud_a, cloud_b)\n",
    "    print(\"output shape is\", mixer_a.shape, mixer_b.shape)\n",
    "    \n",
    "    feat1, feat2 = mixer_a, mixer_b\n",
    "    feature_interaction = FeatureInteraction()\n",
    "    fusion1, fusion2 = feature_interaction(feat1, feat2)\n",
    "    print(\"\\nfusion1 and fusion2 output shapes are\", fusion1.shape, fusion2.shape)\n",
    "    \n",
    "    x = fusion1 # (batches, channels, number of points)\n",
    "    decoder = Decoder(256)\n",
    "    output = decoder(x)\n",
    "    print(\"\\noutput shape cloud A \", output.shape)\n",
    "    \n",
    "    x = fusion2 # (batches, channels, number of points)\n",
    "    decoder = Decoder(256)\n",
    "    output = decoder(x)\n",
    "    print(\"\\noutput shape cloud B \", output.shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649519e6",
   "metadata": {},
   "source": [
    "# Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52118d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.genreg import GenReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e14d245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "output shape cloud A  torch.Size([2, 3, 1024])\n",
      "\n",
      "output shape cloud B  torch.Size([2, 3, 1024])\n"
     ]
    }
   ],
   "source": [
    "model = GenReg()\n",
    "for i,j in enumerate(train_dataloader):\n",
    "    Ag,Bg = model(j[\"input\"], j[\"output\"])\n",
    "    print(\"\\noutput shape cloud A \", Ag.shape)\n",
    "    print(\"\\noutput shape cloud B \", Bg.shape)   \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbbdc5e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4138f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"device\": \"cuda\",\n",
    "    'experiment_name': \"test\",\n",
    "    'batch_size': 2,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_epochs': 10,\n",
    "    'print_every_n': 1000,\n",
    "    'validate_every_n': 500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31f3b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_3depn import main, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2e08907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "its set\n"
     ]
    }
   ],
   "source": [
    "main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "61beebbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "its set\n"
     ]
    }
   ],
   "source": [
    "# Declare device\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available() and config['device'].startswith('cuda'):\n",
    "    device = torch.device(config['device'])\n",
    "    print('Using device:', config['device'])\n",
    "else:\n",
    "    print('Using CPU')\n",
    "\n",
    "# Create Dataloaders\n",
    "train_dataset = ModelNet40('train')\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,   # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "    batch_size=config['batch_size'],   # The size of batches is defined here\n",
    "    shuffle=True,    # Shuffling the order of samples is useful during training to prevent that the network learns to depend on the order of the input data\n",
    "      # This is an implementation detail to speed up data uploading to the GPU\n",
    "    # worker_init_fn=train_dataset.worker_init_fn  TODO: Uncomment this line if you are using shapenet_zip on Google Colab\n",
    ")\n",
    "\n",
    "val_dataset = ModelNet40('cross-category')\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,     # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "    batch_size=config['batch_size'],   # The size of batches is defined here\n",
    "    shuffle=False,   # During validation, shuffling is not necessary anymore\n",
    "    \n",
    "    # worker_init_fn=val_dataset.worker_init_fn  TODO: Uncomment this line if you are using shapenet_zip on Google Colab\n",
    ")\n",
    "\n",
    "# Instantiate model\n",
    "model = GenReg()\n",
    "\n",
    "# Load model if resuming from checkpoint\n",
    "if config['resume_ckpt'] is not None:\n",
    "    model.load_state_dict(torch.load(config['resume_ckpt'], map_location='cpu'))\n",
    "\n",
    "# Move model to specified device\n",
    "model.to(device)\n",
    "\n",
    "print(\"its set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6c51af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from model.genreg import GenReg\n",
    "from data.ModelNet40 import ModelNet40\n",
    "from training.loss import GenRegLoss\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, device, config):\n",
    "    # TODO: Declare loss and move to device; we need both smoothl1 and pure l1 losses here\n",
    "\n",
    "    loss_criterion = GenRegLoss()\n",
    "\n",
    "    # TODO: Declare optimizer with learning rate given in config\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "    # Here, we follow the original implementation to also use a learning rate scheduler -- it simply reduces the learning rate to half every 20 epochs\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "    # TODO: Set model to train\n",
    "    model.train()\n",
    "\n",
    "    best_loss_val = np.inf\n",
    "\n",
    "    # Keep track of running average of train loss for printing\n",
    "    train_loss_running = 0.\n",
    "    \n",
    "\n",
    "    for epoch in range(config['max_epochs']):\n",
    "        for batch_idx, batch in enumerate(train_dataloader):\n",
    "            # TODO: Move batch to device, set optimizer gradients to zero, perform forward pass\n",
    "            # ShapeNet.move_batch_to_device(batch, device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            A = batch['input'].float()\n",
    "            B = batch['output'].float()\n",
    "\n",
    "            Ag, Bg = model(A,B)\n",
    "            \n",
    "\n",
    "            # TODO: Compute loss, Compute gradients, Update network parameters\n",
    "            loss = loss_criterion(A, Ag, B, Bg)\n",
    "            optimizer.step()\n",
    "            \n",
    "          \n",
    "\n",
    "            # Logging\n",
    "            train_loss_running += loss.item()\n",
    "            iteration = epoch * len(train_dataloader) + batch_idx\n",
    "\n",
    "            if iteration % config['print_every_n'] == (config['print_every_n'] - 1):\n",
    "                print(f'[{epoch:03d}/{batch_idx:05d}] train_loss: {train_loss_running / config[\"print_every_n\"]:.6f}')\n",
    "                train_loss_running = 0.\n",
    "\n",
    "            # Validation evaluation and logging\n",
    "            if iteration % config['validate_every_n'] == (config['validate_every_n'] - 1):\n",
    "                # TODO: Set model to eval\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "                # Evaluation on entire validation set\n",
    "                loss_val = 0.\n",
    "                for batch_val in val_dataloader:\n",
    "                    # ShapeNet.move_batch_to_device(batch_val, device)\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        A = batch_val['input']\n",
    "                        B = batch_val['output']\n",
    "\n",
    "                        Ag, Bg = model(A,B)\n",
    "\n",
    "                        \n",
    "\n",
    "                    loss_val += loss_criterion(A, Ag, B, Bg).item()\n",
    "\n",
    "                loss_val /= len(val_dataloader)\n",
    "                if loss_val < best_loss_val:\n",
    "                    torch.save(model.state_dict(), f'./runs/{config[\"experiment_name\"]}/model_best.ckpt')\n",
    "                    best_loss_val = loss_val\n",
    "\n",
    "                print(f'[{epoch:03d}/{batch_idx:05d}] val_loss: {loss_val:.6f} | best_loss_val: {best_loss_val:.6f}')\n",
    "\n",
    "                # TODO: Set model back to train\n",
    "                model.train()\n",
    "\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e923369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted\n",
      "calculating loss\n",
      "loss calculated\n",
      "loss backward\n",
      "finish\n",
      "set\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, device, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ca142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576ceee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec55df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9f9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc80f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef711bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5aa320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d981cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8436332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3035e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51ff03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c65b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a807abd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd4d538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801102c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52671bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e337ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a7af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
